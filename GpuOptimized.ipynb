{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KNN: 100%|██████████| 1/1 [00:32<00:00, 32.43s/it]\n",
      "RandomForest: 100%|██████████| 1/1 [27:41<00:00, 1661.68s/it]\n",
      "GradientBoosting:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "store = pd.read_csv('store.csv')\n",
    "train = pd.read_csv('train.csv', low_memory=False)\n",
    "\n",
    "# Merge the DataFrames on the 'Store' column\n",
    "trainStore = train.merge(store, on='Store').dropna()\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for column in trainStore.columns:\n",
    "    if trainStore[column].dtype == 'object':\n",
    "        trainStore[column] = label_encoder.fit_transform(trainStore[column])\n",
    "\n",
    "# Split the dataframe into input features (X) and target variable (y)\n",
    "X = trainStore.drop(['Sales', 'Date'], axis=1)  # Remove 'Date' column as it's not used\n",
    "y = trainStore['Sales']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# KNN Model with GridSearch\n",
    "param_grid_knn = {'n_neighbors': [3, 5, 7]}\n",
    "with tqdm(desc='KNN', total=1) as pbar_knn:\n",
    "    grid_search_knn = GridSearchCV(KNeighborsRegressor(), param_grid_knn, cv=5)\n",
    "    grid_search_knn.fit(X_train, y_train)\n",
    "    best_knn = grid_search_knn.best_estimator_\n",
    "    pbar_knn.update(1)\n",
    "\n",
    "# RandomForest Model with GridSearch\n",
    "param_grid_rf = {'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7]}\n",
    "with tqdm(desc='RandomForest', total=1) as pbar_rf:\n",
    "    grid_search_rf = GridSearchCV(RandomForestRegressor(), param_grid_rf, cv=5)\n",
    "    grid_search_rf.fit(X_train, y_train)\n",
    "    best_rf = grid_search_rf.best_estimator_\n",
    "    pbar_rf.update(1)\n",
    "\n",
    "# GradientBoosting Model with GridSearch\n",
    "param_grid_gb = {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.5], 'max_depth': [3, 5, 7]}\n",
    "with tqdm(desc='GradientBoosting', total=1) as pbar_gb:\n",
    "    grid_search_gb = GridSearchCV(GradientBoostingRegressor(), param_grid_gb, cv=5)\n",
    "    grid_search_gb.fit(X_train, y_train)\n",
    "    best_gb = grid_search_gb.best_estimator_\n",
    "    pbar_gb.update(1)\n",
    "\n",
    "# DecisionTree Model with GridSearch\n",
    "param_grid_dt = {'max_depth': [3, 5, 7]}\n",
    "with tqdm(desc='DecisionTree', total=1) as pbar_dt:\n",
    "    grid_search_dt = GridSearchCV(DecisionTreeRegressor(), param_grid_dt, cv=5)\n",
    "    grid_search_dt.fit(X_train, y_train)\n",
    "    best_dt = grid_search_dt.best_estimator_\n",
    "    pbar_dt.update(1)\n",
    "\n",
    "# MLPRegressor Model with GridSearch\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(64,), (128,), (64, 32), (128, 64)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'batch_size': [32, 64],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "with tqdm(desc='MLPRegressor', total=1) as pbar_mlp:\n",
    "    grid_search_mlp = GridSearchCV(MLPRegressor(random_state=42), param_grid_mlp, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search_mlp.fit(X_train_scaled, y_train)\n",
    "    best_mlp = grid_search_mlp.best_estimator_\n",
    "    pbar_mlp.update(1)\n",
    "\n",
    "# Predictions and Metrics\n",
    "models = {'KNN': best_knn, 'RandomForest': best_rf, 'GradientBoosting': best_gb, 'DecisionTree': best_dt, 'MLPRegressor': best_mlp}\n",
    "for name, model in models.items():\n",
    "    if name == 'MLPRegressor':\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'{name} Model Metrics:')\n",
    "    print(f'Mean Squared Error (MSE): {mse}')\n",
    "    print(f'R-squared (R2): {r2}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basePython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
