{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Loss: 41374941.6151\n",
      "Epoch 2/20 | Loss: 41375047.2429\n",
      "Epoch 3/20 | Loss: 41374922.0063\n",
      "Epoch 4/20 | Loss: 41375029.6151\n",
      "Epoch 5/20 | Loss: 41374741.2492\n",
      "Epoch 6/20 | Loss: 41376167.4574\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Step 1: Load your data\n",
    "store = pd.read_csv('store.csv')\n",
    "train = pd.read_csv('train.csv', low_memory=False)\n",
    "\n",
    "# Step 2: Merge the DataFrames on the 'Store' column\n",
    "trainStore = train.merge(store, on='Store').dropna()\n",
    "\n",
    "# Step 3: Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for column in trainStore.columns:\n",
    "    if trainStore[column].dtype == 'object':\n",
    "        trainStore[column] = label_encoder.fit_transform(trainStore[column])\n",
    "\n",
    "# Step 4: Replicate the dataset to make it larger\n",
    "replicated_data = pd.concat([trainStore] * 10, ignore_index=True)\n",
    "\n",
    "# Step 5: Split the data into input features (X) and target variable (y)\n",
    "X = replicated_data.drop(['Sales', 'Date'], axis=1)\n",
    "y = replicated_data['Sales']\n",
    "\n",
    "# Step 6: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 8: Move data to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "# Step 9: Convert data to PyTorch tensors and create DataLoader\n",
    "class SalesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 8192\n",
    "\n",
    "train_dataset = SalesDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Step 10: Define your model with more complexity\n",
    "class SalesModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_size, 128)\n",
    "        self.l2 = nn.Linear(128, 128)\n",
    "        self.l3 = nn.Linear(128, 1)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(128)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(128)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = self.relu(self.batch_norm1(self.l1(xb)))\n",
    "        xb = self.relu(self.batch_norm2(self.l2(xb)))\n",
    "        xb = self.l3(xb)\n",
    "        return xb\n",
    "\n",
    "# Step 11: Define the optimizer and loss function\n",
    "model = SalesModel(input_size=X_train_tensor.shape[1]).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "# Step 12: Implement custom PyTorch Estimator\n",
    "class PyTorchEstimator(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, model, optimizer, loss_func, n_epochs=20):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_func = loss_func\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.train()\n",
    "        for epoch in range(self.n_epochs):\n",
    "            losses_in_epoch = []\n",
    "            for x_batch, y_batch in train_loader:\n",
    "\n",
    "                y_hat = self.model(x_batch.to(device))\n",
    "                loss = self.loss_func(y_hat, y_batch.to(device))\n",
    "                losses_in_epoch.append(loss.item())\n",
    "\n",
    "\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            epoch_loss = sum(losses_in_epoch) / len(losses_in_epoch)\n",
    "            print(f\"Epoch {epoch+1}/{self.n_epochs} | Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "            preds = self.model(X_tensor).cpu().numpy()\n",
    "        return preds\n",
    "\n",
    "# Step 13: Hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'n_epochs': [20, 30, 40]\n",
    "}\n",
    "\n",
    "estimator = PyTorchEstimator(model, optimizer, loss_func)\n",
    "\n",
    "grid_search = GridSearchCV(estimator, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 14: Get best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basePython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
